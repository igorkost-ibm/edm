{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import dnnlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-afhqv2-64x64-uncond-vp.pkl\n",
      "CLASSES: 0\n"
     ]
    }
   ],
   "source": [
    "# Load network.\n",
    "\n",
    "model_root = 'https://nvlabs-fi-cdn.nvidia.com/edm/pretrained'\n",
    "# network_pkl = f'{model_root}/edm-cifar10-32x32-cond-vp.pkl'\n",
    "# network_pkl = f'{model_root}/edm-ffhq-64x64-uncond-vp.pkl'\n",
    "network_pkl = f'{model_root}/edm-afhqv2-64x64-uncond-vp.pkl'\n",
    "# network_pkl = f'{model_root}/edm-imagenet-64x64-cond-adm.pkl'\n",
    "\n",
    "device=torch.device('cpu')\n",
    "print(f'Loading network from {network_pkl}')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    net = pickle.load(f)['ema'].to(device)\n",
    "\n",
    "print(f'CLASSES: {net.label_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridw=2\n",
    "gridh=2\n",
    "num_steps=18\n",
    "my_sigma_min=0.002\n",
    "my_sigma_max=90\n",
    "rho=7\n",
    "S_churn=0\n",
    "S_min=0\n",
    "S_max=float('inf')\n",
    "S_noise=1\n",
    "\n",
    "batch_size = gridw * gridh\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class_idx = 417\n",
    "class_labels = None\n",
    "if net.label_dim:\n",
    "    class_labels = torch.eye(net.label_dim, device=device)[torch.randint(net.label_dim, size=[batch_size], device=device)]\n",
    "if class_labels is not None and class_idx is not None:\n",
    "    class_labels[:, :] = 0\n",
    "    class_labels[:, class_idx] = 1\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(arr, path):\n",
    "    print(f'Saving image grid to {path}')\n",
    "    image = (arr * 127.5 + 128).clip(0, 255).to(torch.uint8)\n",
    "    image = image.reshape(gridh, gridw, *image.shape[1:])\n",
    "    image = image.permute(0, 3, 1, 4, 2)\n",
    "    image = image.reshape(gridh * net.img_resolution, gridw * net.img_resolution, net.img_channels)\n",
    "    image = image.cpu().numpy()\n",
    "    PIL.Image.fromarray(image, 'RGB').save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, gridh, gridw, img_resolution, img_channels):\n",
    "    print(f'Loading image grid from {path}')\n",
    "    image = PIL.Image.open(path)#.convert('RGB')\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image, dtype=torch.float64)\n",
    "    image = image.view(gridh, img_resolution, gridw, img_resolution, img_channels)\n",
    "    image = image.permute(0, 2, 4, 1, 3)\n",
    "    image = image.reshape(gridh * gridw, img_channels, img_resolution, img_resolution)\n",
    "    image = (image - 128) / 127.5\n",
    "    return image\n",
    "\n",
    "# a = load_image('./gold.png', 2, 2, 64, 3)\n",
    "# save_image(a, 'saved.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 4 images...\n",
      "Saving image grid to noise-1.png\n"
     ]
    }
   ],
   "source": [
    "# Pick latents and labels.\n",
    "print(f'Generating {batch_size} images...')\n",
    "latents = torch.randn([batch_size, net.img_channels, net.img_resolution, net.img_resolution], device=device)\n",
    "\n",
    "x_orig = latents.to(torch.float64)\n",
    "save_image(x_orig, f'noise-{seed}.png')\n",
    "# x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(dest_path):\n",
    "    \n",
    "    # Adjust noise levels based on what's supported by the network.\n",
    "    sigma_min = max(my_sigma_min, net.sigma_min)\n",
    "    sigma_max = min(my_sigma_max, net.sigma_max)\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=torch.float64, device=device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([net.round_sigma(t_steps), torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    save_image(x_orig, f'{dest_path}-{seed}-00.png')\n",
    "    x_next = x_orig * t_steps[0]\n",
    "    for i, (t_cur, t_next) in tqdm.tqdm(list(enumerate(zip(t_steps[:-1], t_steps[1:]))), unit='step'): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        gamma = min(S_churn / num_steps, np.sqrt(2) - 1) if S_min <= t_cur <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_cur + gamma * t_cur)\n",
    "        x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * torch.randn_like(x_cur)\n",
    "\n",
    "        # Euler step.\n",
    "        denoised = net(x_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (x_hat - denoised) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if i < num_steps - 1:\n",
    "            denoised = net(x_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (x_next - denoised) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "        j = i + 1\n",
    "        if j % 3 == 0:\n",
    "            save_image(x_next, f'{dest_path}-{seed}-{j:02d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-00.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:03<00:19,  1.30s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-03.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:07<00:15,  1.29s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-06.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [00:11<00:11,  1.27s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-09.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:15<00:07,  1.29s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [00:19<00:03,  1.28s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:22<00:00,  1.25s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to cifar-1-18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "denoise('cifar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
