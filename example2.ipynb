{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igorkost/miniconda3/envs/edm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-cifar10-32x32-cond-vp.pkl\n",
      "CLASSES: 10\n"
     ]
    }
   ],
   "source": [
    "# Load network.\n",
    "\n",
    "model_root = 'https://nvlabs-fi-cdn.nvidia.com/edm/pretrained'\n",
    "network_pkl = f'{model_root}/edm-cifar10-32x32-cond-vp.pkl'\n",
    "# network_pkl = f'{model_root}/edm-ffhq-64x64-uncond-vp.pkl'\n",
    "# network_pkl = f'{model_root}/edm-afhqv2-64x64-uncond-vp.pkl'\n",
    "# network_pkl = f'{model_root}/edm-imagenet-64x64-cond-adm.pkl'\n",
    "\n",
    "device=torch.device('cpu')\n",
    "print(f'Loading network from {network_pkl}')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    net = pickle.load(f)['ema'].to(device)\n",
    "\n",
    "print(f'CLASSES: {net.label_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridw=2\n",
    "gridh=2\n",
    "batch_size = gridw * gridh\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class_idx = 4\n",
    "class_labels = None\n",
    "if net.label_dim:\n",
    "    class_labels = torch.eye(net.label_dim, device=device)[torch.randint(net.label_dim, size=[batch_size], device=device)]\n",
    "if class_labels is not None and class_idx is not None:\n",
    "    class_labels[:, :] = 0\n",
    "    class_labels[:, class_idx] = 1\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_png(arr, path):\n",
    "    path = f'{path}.png'\n",
    "    print(f'Saving image grid to {path}')\n",
    "    image = (arr * 127.5 + 128).clip(0, 255).to(torch.uint8)\n",
    "    image = image.reshape(gridh, gridw, *image.shape[1:])\n",
    "    image = image.permute(0, 3, 1, 4, 2)\n",
    "    image = image.reshape(gridh * net.img_resolution, gridw * net.img_resolution, net.img_channels)\n",
    "    image = image.cpu().numpy()\n",
    "    PIL.Image.fromarray(image, 'RGB').save(path)\n",
    "\n",
    "def load_png(path):\n",
    "    path = f'{path}.png'\n",
    "    print(f'Loading image grid from {path}')\n",
    "    image = PIL.Image.open(path)#.convert('RGB')\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image, dtype=torch.float64)\n",
    "    image = image.view(gridh, net.img_resolution, gridw, net.img_resolution, net.img_channels)\n",
    "    image = image.permute(0, 2, 4, 1, 3)\n",
    "    image = image.reshape(gridh * gridw, net.img_channels, net.img_resolution, net.img_resolution)\n",
    "    image = (image - 128) / 127.5\n",
    "    return image\n",
    "\n",
    "# a = load_image('./gold', 2, 2, 64, 3)\n",
    "# save_image(a, 'saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to test.png\n",
      "Saving image grid to test.tiff\n"
     ]
    }
   ],
   "source": [
    "def save_tiff(arr, path):\n",
    "    path = f'{path}.tiff'\n",
    "    print(f'Saving image grid to {path}')\n",
    "    image = (arr * 0.5 + 0.5).to(torch.float32)\n",
    "    image = image.reshape(gridh, gridw, *image.shape[1:])\n",
    "    image = image.permute(0, 3, 1, 4, 2)\n",
    "    image = image.reshape(gridh * net.img_resolution, gridw * net.img_resolution, net.img_channels)\n",
    "    image = image.cpu().numpy()\n",
    "    tifffile.imwrite(path, image, photometric='rgb')\n",
    "\n",
    "def load_tiff(path):\n",
    "    path = f'{path}.tiff'\n",
    "    print(f'Loading image grid from {path}')\n",
    "    image = tifffile.imread(path)\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image, dtype=torch.float64)\n",
    "    image = image.view(gridh, net.img_resolution, gridw, net.img_resolution, net.img_channels)\n",
    "    image = image.permute(0, 2, 4, 1, 3)\n",
    "    image = image.reshape(gridh * gridw, net.img_channels, net.img_resolution, net.img_resolution)\n",
    "    image = (image - 0.5) / 0.5\n",
    "    return image\n",
    "\n",
    "test = torch.randn([batch_size, net.img_channels, net.img_resolution, net.img_resolution], device=device).to(torch.float32)\n",
    "save_png(test, f'test')\n",
    "save_tiff(test, f'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 4 images...\n",
      "Saving image grid to noise.png\n",
      "Saving image grid to noise.tiff\n"
     ]
    }
   ],
   "source": [
    "# Pick latents and labels.\n",
    "print(f'Generating {batch_size} images...')\n",
    "x_orig0 = torch.randn([batch_size, net.img_channels, net.img_resolution, net.img_resolution], device=device).to(torch.float32)\n",
    "\n",
    "save_png(x_orig0, f'noise')\n",
    "save_tiff(x_orig0, f'noise')\n",
    "x_orig = x_orig0\n",
    "# x_orig = load_tiff(f'noise')\n",
    "# save_tiff(x_orig - x_orig0, 'noise.diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-00.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:01<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-03.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:03<00:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-06.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [00:05<00:14,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-09.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [00:07<00:12,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-12.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [00:08<00:10,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-15.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [00:10<00:08,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-18.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [00:12<00:07,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-21.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [00:14<00:05,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-24.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [00:16<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-27.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [00:18<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-30.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:19<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-33.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def edm_sampler(\n",
    "    net, latents, class_labels=None, randn_like=torch.randn_like,\n",
    "    num_steps=33, sigma_min=0.002, sigma_max=80, rho=7,\n",
    "    S_churn=0, S_min=0, S_max=float('inf'), S_noise=1,\n",
    "    dest_path='generated'\n",
    "):\n",
    "    # Adjust noise levels based on what's supported by the network.\n",
    "    sigma_min = max(sigma_min, net.sigma_min)\n",
    "    sigma_max = min(sigma_max, net.sigma_max)\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=torch.float64, device=latents.device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([net.round_sigma(t_steps), torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    save_tiff(latents, f'{dest_path}-00')\n",
    "    x_next = latents.to(torch.float64) * t_steps[0]\n",
    "    for i, (t_cur, t_next) in tqdm.tqdm(list(enumerate(zip(t_steps[:-1], t_steps[1:])))): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        gamma = min(S_churn / num_steps, np.sqrt(2) - 1) if S_min <= t_cur <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_cur + gamma * t_cur)\n",
    "        x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * randn_like(x_cur)\n",
    "\n",
    "        # Euler step.\n",
    "        denoised = net(x_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (x_hat - denoised) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if i < num_steps - 1:\n",
    "            denoised = net(x_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (x_next - denoised) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "        j = i + 1\n",
    "        if j % 3 == 0:\n",
    "            save_tiff(x_next, f'{dest_path}-{j:02d}')\n",
    "\n",
    "    return x_next\n",
    "\n",
    "x = edm_sampler(net, x_orig, dest_path='tre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image grid to tre-99.png\n"
     ]
    }
   ],
   "source": [
    "save_png(x, f'tre-99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
